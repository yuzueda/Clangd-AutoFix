# Clangd-AutoFix: Enhancing LLM Code Reliability in C++

**Clangd-AutoFix** is a hybrid framework designed to automatically repair **header inclusion errors** and **type mismatches** in LLM-generated C++ code. By integrating **Clangd's static analysis**, **rule-based repair**, and **StarCoder's contextual correction**, it significantly improves compilation success and semantic consistency in industrial C++ projects.

---

## 🚀 Features

- **Hybrid Repair Architecture**: Combines rule-based header resolution and LLM-driven type correction
- **Project-Aware Diagnostics**: Uses `compile_commands.json` for context-aware error localization
- **AST-Driven Chunking**: Enables repair of large files (>1K LOC) without context loss
- **Triple-Validation Protocol**: Ensures semantic integrity via:
  - Compilation verification
  - Functional testing
  - AST difference analysis (≤3% delta)

---

## 📦 Quick Start

### Prerequisites

- Python 3.10+
- Jupyter Notebook
- Clangd 17.0.6+
- StarCoder (via Hugging Face Transformers)

### Installation

```bash
pip install transformers libclang jupyter
```

### Running the Framework

Open and execute the main notebook:

```bash
jupyter notebook Clangd-AutoFixer.ipynb
```

---

## 📊 Datasets

### HumanEval-C++ Dataset
- **164 C++ files** generated by LLMs from HumanEval problems
- Contains natural header inclusion and type mismatch errors
- Located in: `generated_cpp_files/`

### Real-World Code Dataset
- **247 files** from industrial C++ projects (not publicly available)
- Includes code from:
  - High-frequency trading systems
  - Autonomous systems (AUTOSAR)
  - Neural network implementations (PyTorch C++)

---

## 🧪 Experimental Setup

### Error Injection for Real-World Code

To evaluate the framework on real-world code, use the error injection notebook:

```bash
jupyter notebook error-inject.ipynb
```

This notebook:
1. Takes real-world C++ code files
2. Randomly injects header inclusion and type mismatch errors
3. Preserves the original project structure and dependencies


### Diagnostic Output Format
Clangd diagnostics are stored in clangd-diagnostics.jsonl with the following structure:

```json
{
  "task_id": "backtracking\\generate_parentheses.cpp",
  "diagnostics": "I[03:42:25.496] clangd version 20.1.3\n...\nE[03:42:25.957] [init_conversion_failed] Line 83: cannot initialize a variable of type 'int' with an rvalue of type 'std::nullptr_t'\nE[03:42:25.957] [undeclared_var_use] Line 89: use of undeclared identifier 'assert'",
  "diag_time_s": 0.68263840675354
}
```

### Evaluation Workflow

1. **Error Injection**: Run `error-inject.ipynb` on real-world code
2. **Repair Process**: Execute `Clangd-AutoFixer.ipynb` on injected files
3. **Semantic Validation**: 
   - Compile repaired code in original environment
   - Run original test suites
   - Verify no behavioral changes

---

## ⚙️ Configuration

The main notebook `Clangd-AutoFixer.ipynb` includes configurable parameters:

### Key Settings
- `USE_RULE_ENGINE`: Enable rule-based header repair (default: True)
- `USE_LLM_REPAIR`: Enable StarCoder for type corrections (default: True)  
- `MAX_CHUNK_TOKENS`: Token limit for AST chunking (default: 1200)
- `AST_DELTA_THRESHOLD`: Maximum allowed semantic change (default: 0.03)

### Model Selection
```python
MODEL_CONFIG = {
    "model_name": "bigcode/starcoder",
    "temperature": 0.2,
    "max_length": 2048
}
```

---

## 📈 Results Reproduction

### HumanEval-C++ Evaluation
1. Open `Clangd-AutoFixer.ipynb`
2. Set dataset path to `datasets/HumanEval-CPP/`
3. Run all cells to reproduce the 78.2% compilation success rate

### Real-World Code Evaluation
1. Use `error-inject.ipynb` to create test cases (if you have real C++ codebases)
2. Run `Clangd-AutoFixer.ipynb` on the injected files
3. Validate by compiling in original project environments

### Expected Results
| Metric | HumanEval-C++ | Real-World Code |
|--------|---------------|-----------------|
| Compilation Success | 78.2% | 75-80% |
| Test Pass Rate | 85.4% | 80-85% |
| AST Delta | ≤3% | ≤3% |

---

## 🏗 Framework Architecture

```
Clangd-AutoFix/
├── Clangd-AutoFixer.ipynb          # Main repair framework
├── error-inject.ipynb              # Error injection for evaluation
├── datasets/
│   ├── HumanEval-CPP/              # 164 LLM-generated C++ files
│   └── real-world/                 # (Not publicly available)
├── type_rules.jsonl            # Symbol-header mapping
├── header_map.jsonl            # StarCoder prompt engineering
```
---

## 📄 License

This project is licensed under the Apache 2.0 License. See the [LICENSE](LICENSE) file for details.

---

## 🙋‍♂️ Contact
For questions or collaborations, please contact:
Xiaoyu Bai – qtdv4019@leeds.ac.uk
Project Link: [[https://github.com/](https://github.com/your-username/Clangd-AutoFix)](https://github.com/yuzueda/yuzueda.github.io)

---

## 💡 Note on Real-World Dataset

The real-world code dataset used in our evaluation contains proprietary code from industrial partners and cannot be publicly distributed. However, the `error-inject.ipynb` notebook provides a methodology for researchers to create similar test cases from their own C++ codebases.

## 🚧 Future Work & Call for Suggestions
Thank you for reading this far! I am currently working on improving the repair of very long code files that exceed the context window of large language models. The current approach involves code chunking and partial parallelization to increase the repair rate and reduce latency.

If you have any ideas or suggestions, please feel free to comment or contact me! This project is still ongoing and will be continuously updated. The goal is to perfect it by the time I turn 100! 😄
